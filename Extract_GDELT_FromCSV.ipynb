{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#File to extract links from the csv file\n",
    "import pandas as pd\n",
    "import urlparse\n",
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "from pandas import DataFrame, read_csv\n",
    "from urlparse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "#Location of the csv file\n",
    "file_loc='C:\\Users\\Dell PC\\Desktop\\GDELT Data\\Express Intent to Cooperate(03)\\\\20161030191601.13715.events.csv'\n",
    "temp_arr=[]\n",
    "file_count=0\n",
    "\n",
    "#Reading the csv file\n",
    "try:\n",
    "    gdelt_event_data=pd.read_csv(file_loc)\n",
    "except IOError as err:\n",
    "    print \"Error while reading csv file\"\n",
    "    print format(err)\n",
    "    exit()\n",
    "\n",
    "\n",
    "#Remove not necessary data. Keep EventCode, EventRootCode and SOURCEURL\n",
    "\n",
    "for col in gdelt_event_data:\n",
    "    if col!='EventCode' and col!='EventRootCode' and col!='SOURCEURL':\n",
    "        gdelt_event_data=gdelt_event_data.drop(col,axis=1)\n",
    "\n",
    "#Retrieve the url hostnames from the DataFrame\n",
    "\n",
    "for ele in gdelt_event_data['SOURCEURL']:\n",
    "\n",
    "    url=urlparse(ele)\n",
    "    temp_arr.append(url.netloc)\n",
    "\n",
    "link_data=pd.DataFrame(data=temp_arr,columns=['host'])\n",
    "\n",
    "#Counting unique data\n",
    "count_data= pd.value_counts(link_data['host'].values,sort=True)\n",
    "\n",
    "\n",
    "#Parse the links provided from the dataframe and append the data to the existing dataframe\n",
    "#Create a new dataframe and write it to the file system\n",
    "for link in gdelt_event_data[\n",
    "    'SOURCEURL']:\n",
    "\n",
    "    try:\n",
    "        temp_arr=[]\n",
    "        temp_text=''\n",
    "        temp_text=link+\"\\n\"\n",
    "        temp_text=temp_text+str(gdelt_event_data['EventCode'][file_count])+\"\\n\"\n",
    "        temp_text=temp_text+str(gdelt_event_data['EventRootCode'][file_count])+\"\\n\"\n",
    "        print link\n",
    "        html_page_stream=requests.get(link)\n",
    "        html_page=BeautifulSoup(html_page_stream.content,'html.parser')\n",
    "\n",
    "        html_p_data=html_page.find_all('p',text=True)\n",
    "\n",
    "        for info in html_p_data:\n",
    "\n",
    "            if len(info.string)>30:\n",
    "                temp_text+=info.string.encode('utf-8')\n",
    "\n",
    "        print temp_text\n",
    "\n",
    "        if len(temp_text)>150:\n",
    "\n",
    "            f=open('C:\\Users\\Dell PC\\Desktop\\GDELT Data\\Express Intent to Cooperate(03)\\Raw Files\\\\'+'_'+str(file_count)+'.txt','w')\n",
    "            f.write(temp_text)\n",
    "\n",
    "\n",
    "            file_count+=1\n",
    "        temp_df=None\n",
    "\n",
    "    except Exception as err:\n",
    "        print \"An error occured while rerieving the article link\"\n",
    "        print format(err)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
